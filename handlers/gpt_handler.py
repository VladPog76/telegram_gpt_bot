"""
–û–±—Ä–æ–±–ª—é–≤–∞—á –∫–æ–º–∞–Ω–¥–∏ /gpt - ChatGPT —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
"""
import logging
import os
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ContextTypes, ConversationHandler
from utils.openai_helper import get_chatgpt_response, transcribe_audio, text_to_speech
from utils.constants import WAITING_GPT_QUESTION

logger = logging.getLogger(__name__)


async def gpt_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ—á–∞—Ç–æ–∫ —Ä–æ–±–æ—Ç–∏ —Å ChatGPT"""
    user = update.effective_user
    logger.info(f"–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user.first_name} ({user.id}) –Ω–∞—Ç–∏—Å–Ω—É–≤ /gpt")

    try:
        with open('images/gpt.jpg', 'rb') as photo:
            await update.message.reply_photo(
                photo=photo,
                caption="ü§ñ ChatGPT —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n\n–ù–∞–ø–∏—à–∏ —Å–≤–æ—î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–º –∞–±–æ –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è üé§"
            )
    except FileNotFoundError:
        await update.message.reply_text(
            "ü§ñ ChatGPT –Ü–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n\n–ù–∞–ø–∏—à–∏ —Å–≤–æ—î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç–æ–º –∞–±–æ –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è üé§"
        )

    return WAITING_GPT_QUESTION


async def gpt_question(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–∏—Ç–∞–Ω–Ω—è –¥–æ GPT"""
    user = update.effective_user
    user_message = update.message.text

    logger.info(f"GPT –ø–∏—Ç–∞–Ω–Ω—è –≤—ñ–¥ {user.first_name}: {user_message}")

    try:
        # –û—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ ChatGPT
        response_text = get_chatgpt_response(user_message)

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –¥–ª—è –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è
        if 'tts_cache' not in context.bot_data:
            context.bot_data['tts_cache'] = {}

        cache_key = f"{user.id}_{update.message.message_id}"
        context.bot_data['tts_cache'][cache_key] = response_text

        # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä—É –∑ –∫–Ω–æ–ø–∫–æ—é –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è
        keyboard = [
            [
                InlineKeyboardButton("‚ùì –©–µ –ø–∏—Ç–∞–Ω–Ω—è", callback_data="gpt_continue"),
                InlineKeyboardButton("üîä –û–∑–≤—É—á–∏—Ç–∏", callback_data=f"tts_{cache_key}")
            ],
            [InlineKeyboardButton("‚ùå –ó–∞–∫—ñ–Ω—á–∏—Ç–∏", callback_data="gpt_end")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        await update.message.reply_text(response_text, reply_markup=reply_markup)

        return WAITING_GPT_QUESTION

    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤ gpt_question: {e}")
        await update.message.reply_text("–í–∏–±–∞—á—Ç–µ, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")
        return WAITING_GPT_QUESTION


async def gpt_button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–∫–∞ –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—è –∫–Ω–æ–ø–æ–∫ —É GPT —Ä–µ–∂–∏–º—ñ"""
    query = update.callback_query
    await query.answer()  # –û–±–æ–≤'—è–∑–∫–æ–≤–æ! –ü—Ä–∏–±–∏—Ä–∞—î "–≥–æ–¥–∏–Ω–Ω–∏–∫"

    user = update.effective_user

    # –õ–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    logger.info(f"–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user.first_name} –Ω–∞—Ç–∏—Å–Ω—É–≤ –∫–Ω–æ–ø–∫—É: {query.data}")

    # –û–∑–≤—É—á—É–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    if query.data.startswith('tts_'):
        cache_key = query.data.replace('tts_', '')

        logger.info(f"–ó–∞–ø–∏—Ç –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è –¥–ª—è –∫–ª—é—á–∞: {cache_key}")

        # –û—Ç—Ä–∏–º—É—î–º–æ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π —Ç–µ–∫—Å—Ç
        tts_cache = context.bot_data.get('tts_cache', {})

        logger.info(f"–î–æ—Å—Ç—É–ø–Ω—ñ –∫–ª—é—á—ñ –≤ –∫–µ—à—ñ: {list(tts_cache.keys())}")

        if cache_key not in tts_cache:
            await query.message.reply_text("‚ùå –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ú–æ–∂–ª–∏–≤–æ, –≤—ñ–Ω –∑–∞—Å—Ç–∞—Ä—ñ–≤.")
            logger.warning(f"–ö–ª—é—á {cache_key} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –∫–µ—à—ñ")
            return WAITING_GPT_QUESTION

        text_to_voice = tts_cache[cache_key]

        logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç –¥–æ–≤–∂–∏–Ω–æ—é {len(text_to_voice)} —Å–∏–º–≤–æ–ª—ñ–≤")

        await query.message.reply_text("üéôÔ∏è –°—Ç–≤–æ—Ä—é—é –∞—É–¥—ñ–æ, –∑–∞—á–µ–∫–∞–π—Ç–µ...")

        # –°—Ç–≤–æ—Ä—é—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–µ —ñ–º'—è —Ñ–∞–π–ª—É
        output_path = f"temp/tts_{user.id}_{cache_key}.mp3"

        try:
            # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É temp —è–∫—â–æ –Ω–µ–º–∞—î
            os.makedirs("temp", exist_ok=True)

            logger.info(f"–ì–µ–Ω–µ—Ä—É—é –∞—É–¥—ñ–æ –≤ —Ñ–∞–π–ª: {output_path}")

            # –ì–µ–Ω–µ—Ä—É—î–º–æ –∞—É–¥—ñ–æ
            if text_to_speech(text_to_voice, output_path):
                logger.info("–ê—É–¥—ñ–æ —É—Å–ø—ñ—à–Ω–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ, –≤—ñ–¥–ø—Ä–∞–≤–ª—è—é...")

                # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≥–æ–ª–æ—Å–æ–≤–µ
                with open(output_path, 'rb') as audio_file:
                    await query.message.reply_voice(voice=audio_file)

                logger.info("–ì–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ")

                # –í–∏–¥–∞–ª—è—î–º–æ —Ñ–∞–π–ª
                os.remove(output_path)
                logger.info("–¢–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª –≤–∏–¥–∞–ª–µ–Ω–æ")

                # –í–∏–¥–∞–ª—è—î–º–æ –∑ –∫–µ—à—É
                del tts_cache[cache_key]
                logger.info("–ó–∞–ø–∏—Å –≤–∏–¥–∞–ª–µ–Ω–æ –∑ –∫–µ—à—É")

                # –î–æ–¥–∞—î–º–æ –∫–Ω–æ–ø–∫–∏ –ø—ñ—Å–ª—è –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è
                keyboard = [
                    [InlineKeyboardButton("‚ùì –©–µ –ø–∏—Ç–∞–Ω–Ω—è", callback_data="gpt_continue")],
                    [InlineKeyboardButton("‚ùå –ó–∞–∫—ñ–Ω—á–∏—Ç–∏", callback_data="gpt_end")]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)

                await query.message.reply_text(
                    "üéôÔ∏è –û–∑–≤—É—á—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n"
                    "–©–æ –¥–∞–ª—ñ?",
                    reply_markup=reply_markup
                )
            else:
                await query.message.reply_text("‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ –∞—É–¥—ñ–æ. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ª–æ–≥–∏ OpenAI.")
                logger.error("text_to_speech –ø–æ–≤–µ—Ä–Ω—É–≤ False")

        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ TTS: {e}", exc_info=True)
            await query.message.reply_text(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            if os.path.exists(output_path):
                os.remove(output_path)

        return WAITING_GPT_QUESTION

    # –ü—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –¥—ñ–∞–ª–æ–≥
    elif query.data == "gpt_continue":
        await query.message.reply_text("‚ùì –ó–∞–¥–∞–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è:")
        return WAITING_GPT_QUESTION

    # –ó–∞–∫—ñ–Ω—á–∏—Ç–∏
    elif query.data == "gpt_end":
        await query.message.reply_text(
            "üëã –î—è–∫—É—é –∑–∞ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è!\n"
            "–©–æ–± –ø–æ–≤–µ—Ä–Ω—É—Ç–∏—Å—è –¥–æ –≥–æ–ª–æ–≤–Ω–æ–≥–æ –º–µ–Ω—é - /start"
        )
        return ConversationHandler.END

    # –Ø–∫—â–æ —â–æ—Å—å —ñ–Ω—à–µ
    else:
        logger.warning(f"–ù–µ–≤—ñ–¥–æ–º–∞ callback_data: {query.data}")
        return WAITING_GPT_QUESTION


async def gpt_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–ª—è—î –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É —Ä–µ–∂–∏–º—ñ /gpt"""
    import os
    from utils.openai_helper import transcribe_audio

    user = update.effective_user
    logger.info(f"–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user.first_name} ({user.id}) –Ω–∞–¥—ñ—Å–ª–∞–≤ –≥–æ–ª–æ—Å –≤ /gpt")

    await update.message.reply_text("üé§ –û–±—Ä–æ–±–ª—è—é –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è...")

    try:
        voice = update.message.voice
        voice_file = await context.bot.get_file(voice.file_id)

        os.makedirs("temp", exist_ok=True)

        voice_path = f"temp/gpt_voice_{user.id}.ogg"
        await voice_file.download_to_drive(voice_path)

        text = transcribe_audio(voice_path)

        if text.startswith("–ü–æ–º–∏–ª–∫–∞"):
            await update.message.reply_text(f"‚ùå {text}")
            os.remove(voice_path)
            return WAITING_GPT_QUESTION

        logger.info(f"–†–æ–∑–ø—ñ–∑–Ω–∞–Ω–∏–π —Ç–µ–∫—Å—Ç —É /gpt: {text}")
        await update.message.reply_text(f"üìù –¢–∏ —Å–∫–∞–∑–∞–≤: {text}\n\n‚è≥ –û–±—Ä–æ–±–ª—è—é –∑–∞–ø–∏—Ç...")

        # –û—Ç—Ä–∏–º—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ ChatGPT
        response_text = get_chatgpt_response(text)

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –¥–ª—è –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è
        if 'tts_cache' not in context.bot_data:
            context.bot_data['tts_cache'] = {}

        cache_key = f"{user.id}_{update.message.message_id}"
        context.bot_data['tts_cache'][cache_key] = response_text

        # –õ–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        logger.info(f"–ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ TTS –∫–µ—à: {cache_key}, —Ç–µ–∫—Å—Ç –¥–æ–≤–∂–∏–Ω–æ—é {len(response_text)} —Å–∏–º–≤–æ–ª—ñ–≤")

        # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä—É –∑ –∫–Ω–æ–ø–∫–æ—é –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è
        keyboard = [
            [
                InlineKeyboardButton("‚ùì –©–µ –ø–∏—Ç–∞–Ω–Ω—è", callback_data="gpt_continue"),
                InlineKeyboardButton("üîä –û–∑–≤—É—á–∏—Ç–∏", callback_data=f"tts_{cache_key}")
            ],
            [InlineKeyboardButton("‚ùå –ó–∞–∫—ñ–Ω—á–∏—Ç–∏", callback_data="gpt_end")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑ –∫–Ω–æ–ø–∫–∞–º–∏
        await update.message.reply_text(response_text, reply_markup=reply_markup)

        logger.info(f"–í—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É {user.first_name} ({user.id})")

        os.remove(voice_path)

    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –≥–æ–ª–æ—Å—É –≤ /gpt: {str(e)}")
        await update.message.reply_text(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏: {str(e)}")

    return WAITING_GPT_QUESTION